
<!doctype html>
<html>
<head>
<title>GET VIDEO</title>
<meta charset="utf-8">
<script>if (typeof module === 'object') {window.module = module; module = undefined;}</script>
<script src="http://static.namenb.com/web/js/?tcbox" type="text/javascript"></script>
<style type="text/css">
body{margin:0;padding:0;background-color:#333;-webkit-app-region: drag;cursor: move;}
</style>
</head>
<body>
<video id="videoface" width="320px" height="240px" autoplay="autoplay" muted></video>
<img src="airplay.png">
<script>
function getMedia() {//获得video摄像头区域
let constraints = {
video: {width: 320, height: 240},
audio: true
};
let video = document.getElementById("videoface");
let promise = navigator.mediaDevices.getUserMedia(constraints);
promise.then(function (MediaStream) {
video.srcObject = MediaStream;
video.play();

});
}
getMedia();

navigator.getUserMedia({ audio: true, video: true }, (stream) => {beginDetect(stream);}, () => {msg(mv);});

function beginDetect(stream){
var audioContext = new AudioContext();
// 将麦克风的声音输入这个对象
mediaStreamSource = audioContext.createMediaStreamSource(stream);
// 创建一个音频分析对象，采样的缓冲区大小为4096，输入和输出都是单声道
scriptProcessor = audioContext.createScriptProcessor(4096,1,1);
// 将该分析对象与麦克风音频进行连接
mediaStreamSource.connect(scriptProcessor);
// 此举无甚效果，仅仅是因为解决 Chrome 自身的 bug
scriptProcessor.connect(audioContext.destination);
// 开始处理音频
scriptProcessor.onaudioprocess = (e) => {
// 获得缓冲区的输入音频，转换为包含了PCM通道数据的32位浮点数组
const buffer = e.inputBuffer.getChannelData(0);
// 获取缓冲区中最大的音量值
const maxVal = Math.max(...buffer);
// 显示音量值
const mv = Math.round(maxVal * 100);
msg(mv);
};
};

</script>
</body>
</html>